{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matidesalegn/Sales-Forecasting/blob/task-2/notebooks/ml_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qu3WwxuLdnB",
        "outputId": "6a1ce7cd-a4dc-4318-e557-10e21d482889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model RMSE: 0.053470820942109865\n"
          ]
        }
      ],
      "source": [
        "# notebooks/02_ml_modeling.ipynb\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define class for ML Model\n",
        "class MLModel:\n",
        "    def __init__(self, train_path, test_path):\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "        self.model = None\n",
        "        self.pipeline = None\n",
        "\n",
        "    def load_data(self):\n",
        "        dtype_spec = {\n",
        "            'StateHoliday': str,\n",
        "            'StoreType': str,\n",
        "            'Assortment': str,\n",
        "            'PromoInterval': str\n",
        "        }\n",
        "        self.train = pd.read_csv(self.train_path, dtype=dtype_spec)\n",
        "        self.test = pd.read_csv(self.test_path, dtype=dtype_spec)\n",
        "        self.X_train = self.train.drop(columns=['Sales'])\n",
        "        self.y_train = self.train['Sales']\n",
        "        self.X_test = self.test.copy()  # Sales column not available in test data\n",
        "        logger.info(\"Data loaded successfully\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        # Identify numerical and categorical columns\n",
        "        numerical_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        categorical_cols = self.X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "        # Ensure all categorical columns are of string type\n",
        "        self.X_train[categorical_cols] = self.X_train[categorical_cols].astype(str)\n",
        "        self.X_test[categorical_cols] = self.X_test[categorical_cols].astype(str)\n",
        "\n",
        "        # Define preprocessing steps\n",
        "        numerical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "\n",
        "        # Bundle preprocessing for numerical and categorical data\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols)\n",
        "            ])\n",
        "\n",
        "        self.pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                        ('model', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
        "        logger.info(\"Preprocessing pipeline created\")\n",
        "\n",
        "    def build_model(self):\n",
        "        self.pipeline.fit(self.X_train, self.y_train)\n",
        "        logger.info(\"Model trained successfully\")\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        predictions = self.pipeline.predict(self.X_train)\n",
        "        mse = mean_squared_error(self.y_train, predictions)\n",
        "        rmse = mean_squared_error(self.y_train, predictions, squared=False)\n",
        "        logger.info(f\"Model evaluation complete. RMSE: {rmse}\")\n",
        "        return rmse\n",
        "\n",
        "    def save_model(self):\n",
        "        model_dir = 'data/models'\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "        model_path = os.path.join(model_dir, f\"model-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.pkl\")\n",
        "        joblib.dump(self.pipeline, model_path)\n",
        "        logger.info(f\"Model saved at {model_path}\")\n",
        "\n",
        "    def run(self):\n",
        "        self.load_data()\n",
        "        self.preprocess()\n",
        "        self.build_model()\n",
        "        rmse = self.evaluate_model()\n",
        "        self.save_model()\n",
        "        return rmse\n",
        "\n",
        "# Create instance of MLModel\n",
        "model = MLModel('train_processed.csv', 'test_processed.csv')\n",
        "\n",
        "# Run the model pipeline\n",
        "rmse = model.run()\n",
        "print(f\"Model RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define class for ML Model\n",
        "class MLModel:\n",
        "    def __init__(self, train_path, test_path):\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "        self.model = None\n",
        "        self.pipeline = None\n",
        "\n",
        "    def load_data(self):\n",
        "        dtype_spec = {\n",
        "            'StateHoliday': str,\n",
        "            'StoreType': str,\n",
        "            'Assortment': str,\n",
        "            'PromoInterval': str\n",
        "        }\n",
        "        self.train = pd.read_csv(self.train_path, dtype=dtype_spec)\n",
        "        self.test = pd.read_csv(self.test_path, dtype=dtype_spec)\n",
        "        self.X_train = self.train.drop(columns=['Sales'])\n",
        "        self.y_train = self.train['Sales']\n",
        "        self.X_test = self.test.copy()  # Sales column not available in test data\n",
        "        logger.info(\"Data loaded successfully\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        # Extract datetime features\n",
        "        def extract_date_features(df):\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df['Year'] = df['Date'].dt.year\n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            df['Day'] = df['Date'].dt.day\n",
        "            df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
        "            df['Weekday'] = df['Date'].dt.weekday\n",
        "            df['IsWeekend'] = df['Weekday'] >= 5\n",
        "            df['MonthStart'] = df['Day'] <= 10\n",
        "            df['MonthMid'] = (df['Day'] > 10) & (df['Day'] <= 20)\n",
        "            df['MonthEnd'] = df['Day'] > 20\n",
        "            return df\n",
        "\n",
        "        self.X_train = extract_date_features(self.X_train)\n",
        "        self.X_test = extract_date_features(self.X_test)\n",
        "\n",
        "        # Identify numerical and categorical columns\n",
        "        numerical_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        categorical_cols = self.X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "        # Ensure all categorical columns are of string type\n",
        "        self.X_train[categorical_cols] = self.X_train[categorical_cols].astype(str)\n",
        "        self.X_test[categorical_cols] = self.X_test[categorical_cols].astype(str)\n",
        "\n",
        "        # Define preprocessing steps\n",
        "        numerical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "\n",
        "        # Bundle preprocessing for numerical and categorical data\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols)\n",
        "            ])\n",
        "\n",
        "        self.pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                        ('model', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
        "        logger.info(\"Preprocessing pipeline created\")\n",
        "\n",
        "    def build_model(self):\n",
        "        self.pipeline.fit(self.X_train, self.y_train)\n",
        "        logger.info(\"Model trained successfully\")\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        predictions = self.pipeline.predict(self.X_train)\n",
        "        mse = mean_squared_error(self.y_train, predictions)\n",
        "        rmse = mean_squared_error(self.y_train, predictions, squared=False)\n",
        "        logger.info(f\"Model evaluation complete. RMSE: {rmse}\")\n",
        "        return rmse\n",
        "\n",
        "    def save_model(self):\n",
        "        model_dir = 'models'\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "        model_path = os.path.join(model_dir, f\"model-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.pkl\")\n",
        "        joblib.dump(self.pipeline, model_path)\n",
        "        logger.info(f\"Model saved at {model_path}\")\n",
        "\n",
        "    def run(self):\n",
        "        self.load_data()\n",
        "        self.preprocess()\n",
        "        self.build_model()\n",
        "        rmse = self.evaluate_model()\n",
        "        self.save_model()\n",
        "        return rmse\n",
        "\n",
        "# Create instance of MLModel\n",
        "model = MLModel('train_processed.csv', 'test_processed.csv')\n",
        "\n",
        "# Run the model pipeline\n",
        "rmse = model.run()\n",
        "print(f\"Model RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "0fda2bnrbZRM",
        "outputId": "02a965c6-bed7-48e2-cfe3-4678d5d33b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model RMSE: 0.04896290100204645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define class for ML Model\n",
        "class MLModel:\n",
        "    def __init__(self, train_path, test_path):\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "        self.model = None\n",
        "        self.pipeline = None\n",
        "\n",
        "    def load_data(self):\n",
        "        dtype_spec = {\n",
        "            'StateHoliday': str,\n",
        "            'StoreType': str,\n",
        "            'Assortment': str,\n",
        "            'PromoInterval': str\n",
        "        }\n",
        "        self.train = pd.read_csv(self.train_path, dtype=dtype_spec)\n",
        "        self.test = pd.read_csv(self.test_path, dtype=dtype_spec)\n",
        "        self.X_train = self.train.drop(columns=['Sales'])\n",
        "        self.y_train = self.train['Sales']\n",
        "        self.X_test = self.test.copy()  # Sales column not available in test data\n",
        "        logger.info(\"Data loaded successfully\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        # Extract datetime features\n",
        "        def extract_date_features(df):\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df['Year'] = df['Date'].dt.year\n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            df['Day'] = df['Date'].dt.day\n",
        "            df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
        "            df['Weekday'] = df['Date'].dt.weekday\n",
        "            df['IsWeekend'] = df['Weekday'] >= 5\n",
        "            df['MonthStart'] = df['Day'] <= 10\n",
        "            df['MonthMid'] = (df['Day'] > 10) & (df['Day'] <= 20)\n",
        "            df['MonthEnd'] = df['Day'] > 20\n",
        "            # Placeholder for days to holidays and days after holidays\n",
        "            df['DaysToHoliday'] = 0  # Implement actual logic\n",
        "            df['DaysAfterHoliday'] = 0  # Implement actual logic\n",
        "            return df\n",
        "\n",
        "        self.X_train = extract_date_features(self.X_train)\n",
        "        self.X_test = extract_date_features(self.X_test)\n",
        "\n",
        "        # Identify numerical and categorical columns\n",
        "        numerical_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        categorical_cols = self.X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "        # Ensure all categorical columns are of string type\n",
        "        self.X_train[categorical_cols] = self.X_train[categorical_cols].astype(str)\n",
        "        self.X_test[categorical_cols] = self.X_test[categorical_cols].astype(str)\n",
        "\n",
        "        # Define preprocessing steps\n",
        "        numerical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "\n",
        "        # Bundle preprocessing for numerical and categorical data\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numerical_transformer, numerical_cols),\n",
        "                ('cat', categorical_transformer, categorical_cols)\n",
        "            ])\n",
        "\n",
        "        self.pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                        ('model', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
        "        logger.info(\"Preprocessing pipeline created\")\n",
        "\n",
        "    def build_model(self):\n",
        "        self.pipeline.fit(self.X_train, self.y_train)\n",
        "        logger.info(\"Model trained successfully\")\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        predictions = self.pipeline.predict(self.X_train)\n",
        "        mse = mean_squared_error(self.y_train, predictions)\n",
        "        rmse = mean_squared_error(self.y_train, predictions, squared=False)\n",
        "        logger.info(f\"Model evaluation complete. RMSE: {rmse}\")\n",
        "        return rmse\n",
        "\n",
        "    def get_feature_importance(self):\n",
        "        feature_importances = self.pipeline.named_steps['model'].feature_importances_\n",
        "        features = self.pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out().tolist()\n",
        "        features.extend(self.X_train.select_dtypes(include=['int64', 'float64']).columns.tolist())\n",
        "        logger.debug(f\"Features: {features}\")\n",
        "        logger.debug(f\"Feature Importances: {feature_importances}\")\n",
        "        if len(features) != len(feature_importances):\n",
        "            logger.error(\"Feature length mismatch with feature importances length\")\n",
        "            raise ValueError(\"Feature length mismatch with feature importances length\")\n",
        "        importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "        return importance_df\n",
        "\n",
        "    def estimate_confidence_intervals(self, n_bootstrap=1000):\n",
        "        # Placeholder for confidence interval estimation logic\n",
        "        pass\n",
        "\n",
        "    def save_model(self):\n",
        "        model_dir = 'models'\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "        model_path = os.path.join(model_dir, f\"model-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.pkl\")\n",
        "        joblib.dump(self.pipeline, model_path)\n",
        "        logger.info(f\"Model saved at {model_path}\")\n",
        "\n",
        "    def run(self):\n",
        "        self.load_data()\n",
        "        self.preprocess()\n",
        "        self.build_model()\n",
        "        rmse = self.evaluate_model()\n",
        "        feature_importance = self.get_feature_importance()\n",
        "        print(feature_importance)  # Display feature importance\n",
        "        self.estimate_confidence_intervals()\n",
        "        self.save_model()\n",
        "        return rmse\n",
        "\n",
        "# Create instance of MLModel\n",
        "model = MLModel('train_processed.csv', 'test_processed.csv')\n",
        "\n",
        "# Run the model pipeline\n",
        "rmse = model.run()\n",
        "print(f\"Model RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "rEZlcidS0jPh",
        "outputId": "08a98f0b-7a6d-4397-de90-41e528096442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           Feature    Importance\n",
            "2                   StateHoliday_b  8.640474e-01\n",
            "6                      StoreType_c  2.691505e-02\n",
            "21                  MonthEnd_False  2.380847e-02\n",
            "4                      StoreType_a  1.756299e-02\n",
            "0                   StateHoliday_0  1.526043e-02\n",
            "23                           Store  9.580827e-03\n",
            "10                    Assortment_c  6.364170e-03\n",
            "8                     Assortment_a  6.050833e-03\n",
            "19                  MonthMid_False  6.036567e-03\n",
            "1                   StateHoliday_a  5.697228e-03\n",
            "7                      StoreType_d  5.269025e-03\n",
            "11                 PromoInterval_0  3.094098e-03\n",
            "24                       DayOfWeek  1.244298e-03\n",
            "22                   MonthEnd_True  1.231658e-03\n",
            "27                           Promo  9.897917e-04\n",
            "18                 MonthStart_True  7.871828e-04\n",
            "5                      StoreType_b  7.787554e-04\n",
            "25                       Customers  6.823956e-04\n",
            "20                   MonthMid_True  5.682947e-04\n",
            "26                            Open  5.295354e-04\n",
            "28                   SchoolHoliday  4.225631e-04\n",
            "36                DaysAfterHoliday  3.923117e-04\n",
            "35                   DaysToHoliday  3.890322e-04\n",
            "9                     Assortment_b  3.552263e-04\n",
            "34                 Promo2SinceYear  3.189682e-04\n",
            "33                 Promo2SinceWeek  3.189500e-04\n",
            "31        CompetitionOpenSinceYear  3.177664e-04\n",
            "32                          Promo2  3.130436e-04\n",
            "30       CompetitionOpenSinceMonth  2.852461e-04\n",
            "29             CompetitionDistance  2.642325e-04\n",
            "14  PromoInterval_Mar,Jun,Sept,Dec  1.034005e-04\n",
            "15                 IsWeekend_False  1.193779e-05\n",
            "17                MonthStart_False  5.854282e-06\n",
            "16                  IsWeekend_True  2.416945e-06\n",
            "3                   StateHoliday_c  1.899287e-16\n",
            "12   PromoInterval_Feb,May,Aug,Nov  0.000000e+00\n",
            "13   PromoInterval_Jan,Apr,Jul,Oct  0.000000e+00\n",
            "Model RMSE: 0.04895498885965404\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}