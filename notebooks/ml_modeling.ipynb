{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Data loaded successfully\n",
      "INFO:__main__:Preprocessing pipeline created\n"
     ]
    }
   ],
   "source": [
    "# notebooks/02_ml_modeling.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define class for ML Model\n",
    "class MLModel:\n",
    "    def __init__(self, train_path, test_path):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.model = None\n",
    "        self.pipeline = None\n",
    "\n",
    "    def load_data(self):\n",
    "        dtype_spec = {\n",
    "            'StateHoliday': str,\n",
    "            'StoreType': str,\n",
    "            'Assortment': str,\n",
    "            'PromoInterval': str\n",
    "        }\n",
    "        self.train = pd.read_csv(self.train_path, dtype=dtype_spec)\n",
    "        self.test = pd.read_csv(self.test_path, dtype=dtype_spec)\n",
    "        self.X_train = self.train.drop(columns=['Sales'])\n",
    "        self.y_train = self.train['Sales']\n",
    "        self.X_test = self.test.copy()  # Sales column not available in test data\n",
    "        logger.info(\"Data loaded successfully\")\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Identify numerical and categorical columns\n",
    "        numerical_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_cols = self.X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "        \n",
    "        # Ensure all categorical columns are of string type\n",
    "        self.X_train[categorical_cols] = self.X_train[categorical_cols].astype(str)\n",
    "        self.X_test[categorical_cols] = self.X_test[categorical_cols].astype(str)\n",
    "        \n",
    "        # Define preprocessing steps\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        \n",
    "        # Bundle preprocessing for numerical and categorical data\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, numerical_cols),\n",
    "                ('cat', categorical_transformer, categorical_cols)\n",
    "            ])\n",
    "        \n",
    "        self.pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                        ('model', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "        logger.info(\"Preprocessing pipeline created\")\n",
    "\n",
    "    def build_model(self):\n",
    "        self.pipeline.fit(self.X_train, self.y_train)\n",
    "        logger.info(\"Model trained successfully\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        predictions = self.pipeline.predict(self.X_train)\n",
    "        mse = mean_squared_error(self.y_train, predictions)\n",
    "        rmse = mean_squared_error(self.y_train, predictions, squared=False)\n",
    "        logger.info(f\"Model evaluation complete. RMSE: {rmse}\")\n",
    "        return rmse\n",
    "\n",
    "    def save_model(self):\n",
    "        model_dir = 'data/models'\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model_path = os.path.join(model_dir, f\"model-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.pkl\")\n",
    "        joblib.dump(self.pipeline, model_path)\n",
    "        logger.info(f\"Model saved at {model_path}\")\n",
    "\n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.preprocess()\n",
    "        self.build_model()\n",
    "        rmse = self.evaluate_model()\n",
    "        self.save_model()\n",
    "        return rmse\n",
    "\n",
    "# Create instance of MLModel\n",
    "model = MLModel('../data/processed/train_processed.csv', '../data/processed/test_processed.csv')\n",
    "\n",
    "# Run the model pipeline\n",
    "rmse = model.run()\n",
    "print(f\"Model RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
